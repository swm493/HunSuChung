import torch
from rvc_python.infer import RVCInference
import edge_tts
import asyncio

TEXT = "ê·¸ê±°ê·¸ë ‡ê²Œí•˜ëŠ”ê±°ì•„ë‹Œë°ì—"
VOICE = "ko-KR-SunHiNeural"  # ì—¬ì„± í™”ì
OUTPUT = "output.wav"        # ì €ì¥ íŒŒì¼

async def create_tts(text=TEXT):
    communicate = edge_tts.Communicate(
        text=text,
        voice=VOICE,
        #style=STYLE,          # ìƒëµ ê°€ëŠ¥
        rate="+30%",           # ì†ë„ (ì˜ˆ: +10%, -20%)
        #pitch="+0%"           # ìŒì¡° (ì˜ˆ: +5%, -5%)
    )
    await communicate.save(OUTPUT)

def generate_tts(text):
    asyncio.run(create_tts(text))

device="cuda" if torch.cuda.is_available() else "cpu"
# ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
def run_voice_assistant():

    # output.wav â†’ Hubert feature ì¶”ì¶œ
    rvc_modelname = "ikuyo_kita"
    rvc_modelpath = "models/" + rvc_modelname + "/" + rvc_modelname
    rvc = RVCInference(device=device)
    rvc.set_params(f0up_key=7, protect=0.5)
    rvc.load_model(rvc_modelpath + ".pth", index_path=rvc_modelpath + ".index")  # ğŸŸ¡ ì—¬ê¸° ì‹¤ì œ ëª¨ë¸ ê²½ë¡œ ë„£ê¸°
    rvc.infer_file("output.wav", "final_output.wav")  # RVC ë³€í™˜ ì™„ë£Œ


if __name__ == "__main__":
    run_voice_assistant()